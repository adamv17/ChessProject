{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2007fc0a-d430-4027-a418-841b33c6ade1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\USER\\anaconda3\\envs\\chesnn\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba8aa5d-30bc-4f64-8eaa-cfd45c4f7a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cc3a55b8c2d91eb2\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cc3a55b8c2d91eb2\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#taskkill /IM \"tensorboard.exe\" /F\n",
    "!rmdir /S /Q %temp%\\.tensorboard-info\n",
    "%tensorboard --logdir=runs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6daf1b5-3041-4312-9860-4521a347ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "data_params = {'batch_size':128, \n",
    "               'shuffle':True}\n",
    "\n",
    "# validation params\n",
    "val_params = {'batch_size': 1, 'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08478b4e-3565-4977-ae10-8e5d833a09dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# dataset \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, evals, games, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.evals = evals\n",
    "        self.games = games\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "         # Load data and get label\n",
    "        X = self.evals[ID]\n",
    "        X2 = self.games[ID]\n",
    "        y = self.labels[ID]\n",
    "        in_data = torch.empty((X.size()[0], 65))\n",
    "        in_data[:, 0:64] = X2\n",
    "        in_data[:, 64] = X\n",
    "        return torch.flatten(in_data), y\n",
    "    \n",
    "samples = torch.load('../data/X.pt')\n",
    "partition = {'train': list(range(17000)), 'dev': list(range(17000, 18000)), 'test': []}\n",
    "games = torch.load('../data/X2.pt')\n",
    "labels = torch.load('../data/Y.pt')\n",
    "# data loader\n",
    "training_set = Dataset(samples, games, partition['train'], labels)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **data_params)\n",
    "\n",
    "validation_set = Dataset(samples, games, partition['dev'], labels)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **val_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb28f5d2-22c4-4b4e-b988-0adf02bb80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ef566ac-64eb-4936-94f3-87c7a80c058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn model\n",
    "# class EloNN(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.evl = torch.nn.Sequential(\n",
    "#             torch.nn.Conv1d(in_channels=1, out_channels=200, kernel_size=20),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Flatten(),\n",
    "#             torch.nn.Linear(in_features=16200, out_features=50),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Linear(in_features=50, out_features=50),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#         )\n",
    "#         self.game = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(in_features=64, out_features=512),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Linear(in_features=512, out_features=128),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Linear(in_features=128, out_features=64),\n",
    "#             torch.nn.ReLU(inplace=True)\n",
    "#         )\n",
    "#         self.fc_combine = torch.nn.Sequential(\n",
    "#             torch.nn.Linear(in_features=6450, out_features=100),\n",
    "#             torch.nn.ReLU(inplace=True),\n",
    "#             torch.nn.Linear(in_features=100, out_features=2),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, input1, input2):\n",
    "#         e = self.evl(input1)\n",
    "#         g = self.game(input2)\n",
    "#         combined = torch.cat((g.view(g.size(0), -1),\n",
    "#                               e.view(e.size(0), -1)), dim=1)\n",
    "#         out = self.fc_combine(combined)\n",
    "#         return out\n",
    "\n",
    "class EloNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=6500, out_features=200),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=200, out_features=150),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(in_features=150, out_features=40),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(in_features=40, out_features=2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        return self.layers(inp)\n",
    "    \n",
    "model = EloNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94e8de34-74bb-46b1-90a7-52367300d921",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-dcfdc47b04b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m ]\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtheme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHEMES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'blue'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'elonn_hiddenlayer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\hiddenlayer\\graph.py\u001b[0m in \u001b[0;36mbuild_graph\u001b[1;34m(model, args, input_names, transforms, framework_transforms)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpytorch_builder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFRAMEWORK_TRANSFORMS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Argument args must be provided for Pytorch models.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mimport_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tensorflow\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtf_builder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimport_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFRAMEWORK_TRANSFORMS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\hiddenlayer\\pytorch_builder.py\u001b[0m in \u001b[0;36mimport_graph\u001b[1;34m(hl_graph, model, args, input_names, verbose)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;31m# Run the Pytorch graph to get a trace and generate a graph from it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_trace_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[0mtorch_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimize_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOperatorExportTypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mONNX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36m_get_trace_graph\u001b[1;34m(f, args, kwargs, strict, _force_outplace, return_inputs, _return_inputs_states)\u001b[0m\n\u001b[0;32m   1164\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1165\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1166\u001b[1;33m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mONNXTracedModule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_return_inputs_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1167\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         graph, out = torch._C._create_graph_by_tracing(\n\u001b[0m\u001b[0;32m    128\u001b[0m             \u001b[0mwrapper\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0min_vars\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodule_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torch\\jit\\_trace.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mouts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mtrace_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_return_inputs_states\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[0minputs_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minputs_states\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrace_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_slow_forward\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1088\u001b[0m                 \u001b[0mrecording_scopes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrecording_scopes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "import hiddenlayer as hl\n",
    "\n",
    "transforms = [\n",
    "    hl.transforms.Fold(\"\"\"(Transpose > MatMul > Add)\"\"\", \"Linear\", \"Linear\"),\n",
    "    hl.transforms.Fold(\"\"\"Linear > Relu\"\"\", \"LinRe\"),\n",
    "    # hl.transforms.Fold(\"Shape >  Gather > Unsqueeze > Concat > Reshape > Concat\", \"Con\", \"Concat\"),\n",
    "    hl.transforms.FoldDuplicates()\n",
    "]\n",
    "\n",
    "graph = hl.build_graph(model, (torch.zeros(128, 1, 100), torch.zeros(128, 100, 64)), transforms=transforms)\n",
    "graph.theme = hl.graph.THEMES['blue'].copy()\n",
    "graph.save('elonn_hiddenlayer', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5a7958-f66a-4420-ab64-e4f5593a7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "learning_rate=1e-3\n",
    "epochs=50 # 2000\n",
    "l2=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dad611c-f7de-46c7-b178-e3ad371da2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def get_num_correct(predicted, actual):\n",
    "    count = 0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if abs(p[0] - actual[i][0]) < 100 and abs(p[1] - actual[i][1]) < 100:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0890508-58f8-44a0-be72-80dbfc60431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_correct: 1953 loss: 9682963.6484375\n",
      "epoch: 1 total_correct: 2211 loss: 8816967.4140625\n",
      "epoch: 2 total_correct: 2168 loss: 8681464.1875\n",
      "epoch: 3 total_correct: 2097 loss: 8576847.31640625\n",
      "epoch: 4 total_correct: 2182 loss: 8672834.09375\n",
      "epoch: 5 total_correct: 2211 loss: 8507356.5625\n",
      "epoch: 6 total_correct: 2164 loss: 8574709.65234375\n",
      "epoch: 7 total_correct: 2244 loss: 8464366.85546875\n",
      "epoch: 8 total_correct: 2263 loss: 8138680.55859375\n",
      "epoch: 9 total_correct: 2268 loss: 8092943.578125\n",
      "epoch: 10 total_correct: 2272 loss: 7931125.890625\n",
      "epoch: 11 total_correct: 2311 loss: 7983787.40625\n",
      "epoch: 12 total_correct: 2263 loss: 8123928.55078125\n",
      "epoch: 13 total_correct: 2306 loss: 8056390.46484375\n",
      "epoch: 14 total_correct: 2215 loss: 7885904.85546875\n",
      "epoch: 15 total_correct: 2260 loss: 7994870.21484375\n",
      "epoch: 16 total_correct: 2260 loss: 7880565.0859375\n",
      "epoch: 17 total_correct: 2355 loss: 7787206.5625\n",
      "epoch: 18 total_correct: 2352 loss: 7548090.23046875\n",
      "epoch: 19 total_correct: 2298 loss: 7838870.27734375\n",
      "epoch: 20 total_correct: 2322 loss: 7503516.3828125\n",
      "epoch: 21 total_correct: 2297 loss: 7620352.97265625\n",
      "epoch: 22 total_correct: 2386 loss: 7547129.41796875\n",
      "epoch: 23 total_correct: 2410 loss: 7530743.5625\n",
      "epoch: 24 total_correct: 2443 loss: 7453917.8046875\n",
      "epoch: 25 total_correct: 2380 loss: 7768120.421875\n",
      "epoch: 26 total_correct: 2441 loss: 7327165.33203125\n",
      "epoch: 27 total_correct: 2490 loss: 7211258.015625\n",
      "epoch: 28 total_correct: 2491 loss: 7242979.83203125\n",
      "epoch: 29 total_correct: 2527 loss: 7288072.125\n",
      "epoch: 30 total_correct: 2462 loss: 7364030.84765625\n",
      "epoch: 31 total_correct: 2477 loss: 7230113.79296875\n",
      "epoch: 32 total_correct: 2476 loss: 7140601.234375\n",
      "epoch: 33 total_correct: 2517 loss: 7035481.81640625\n",
      "epoch: 34 total_correct: 2545 loss: 7146329.83984375\n",
      "epoch: 35 total_correct: 2600 loss: 7199618.45703125\n",
      "epoch: 36 total_correct: 2590 loss: 6948265.28515625\n",
      "epoch: 37 total_correct: 2575 loss: 6979022.71875\n",
      "epoch: 38 total_correct: 2605 loss: 6899161.921875\n",
      "epoch: 39 total_correct: 2532 loss: 7006910.1640625\n",
      "epoch: 40 total_correct: 2644 loss: 6901709.03515625\n",
      "epoch: 41 total_correct: 2573 loss: 7050039.5546875\n",
      "epoch: 42 total_correct: 2624 loss: 6734098.28515625\n",
      "epoch: 43 total_correct: 2660 loss: 6799943.3671875\n",
      "epoch: 44 total_correct: 2614 loss: 6995040.19921875\n",
      "epoch: 45 total_correct: 2620 loss: 6808702.6484375\n",
      "epoch: 46 total_correct: 2673 loss: 6814440.74609375\n",
      "epoch: 47 total_correct: 2664 loss: 6725222.6953125\n",
      "epoch: 48 total_correct: 2547 loss: 6814582.8203125\n",
      "epoch: 49 total_correct: 2708 loss: 6592818.5546875\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('eval_game_model_simple_better.pt'))\n",
    "model.train()\n",
    "model.to(device)\n",
    "\n",
    "tb = SummaryWriter()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "tb = SummaryWriter()\n",
    "has_graphed = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for inputs, labels in training_generator:\n",
    "        # evals, games, labels = evals.float(), games.float(), labels.float()\n",
    "        # evals = evals[:, None, :]\n",
    "        # evals, games, labels = evals.to(device), games.to(device), labels.to(device)\n",
    "        inputs, labels = inputs.float().to(device), labels.float().to(device)\n",
    "        preds = model(inputs)\n",
    "        if epoch == 0 and not has_graphed:\n",
    "            tb.add_graph(model, inputs)\n",
    "            has_graphed = True\n",
    "            \n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct / len(training_generator), epoch)\n",
    "\n",
    "    tb.add_hparams(\n",
    "        {\"lr\": learning_rate, \"bsize\": data_params['batch_size'], \"shuffle\": data_params['shuffle']},\n",
    "        {\n",
    "            \"accuracy\": total_correct / len(training_generator),\n",
    "            \"loss\": total_loss,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()\n",
    "torch.save(model.state_dict(), 'eval_game_model_simple_better.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ebdc9ea-fb07-4fea-b6d5-2b9a448ce4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "statistics: \n",
      "std white = 184.04862998434098, std black = 184.80604373867826 \n",
      "mean white = 238.39352465820312, mean black = 235.82322204589843 \n",
      "max white = 1227.962646484375, max black = 1129.4755859375 \n",
      "min white = 0.4154052734375, min black = 0.251708984375\n",
      "total correct 94\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# validate model\n",
    "model.load_state_dict(torch.load('eval_game_model_simple_better.pt'))\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "dev_num = len(validation_generator)\n",
    "predictions = np.empty((dev_num, 2))\n",
    "divs_white = np.empty(dev_num)\n",
    "divs_black = np.empty(dev_num)\n",
    "i = 0\n",
    "total_correct = 0\n",
    "for val_inputs, val_label in validation_generator:\n",
    "    # val_input, val_games = val_input.float(), val_games.float()\n",
    "    # val_input = val_input[:, None, :]\n",
    "    # val_input, val_games = val_input.to(device), val_games.to(device)\n",
    "    val_inputs = val_inputs.float().to(device)\n",
    "    y_hat = model(val_inputs)\n",
    "    y_hat = y_hat.detach().numpy()[0]\n",
    "    val_label = val_label.float().detach().numpy()[0]\n",
    "    div_white = abs(y_hat[0] - val_label[0])\n",
    "    div_black = abs(y_hat[1] - val_label[1])\n",
    "    if div_white < 100 and div_black < 100:\n",
    "        total_correct = total_correct + 1\n",
    "    predictions[i] = y_hat\n",
    "    divs_white[i] = div_white\n",
    "    divs_black[i] = div_black\n",
    "    i = i + 1\n",
    "str_res = f'\\nstatistics: \\nstd white = {np.std(divs_white)}, std black = {np.std(divs_black)} \\n' \\\n",
    "      f'mean white = {np.mean(divs_white)}, mean black = {np.mean(divs_black)} \\n' \\\n",
    "      f'max white = {np.max(divs_white)}, max black = {np.max(divs_black)} \\n' \\\n",
    "      f'min white = {np.min(divs_white)}, min black = {np.min(divs_black)}'\n",
    "print(str_res)\n",
    "print(f'total correct {total_correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a2e3c-18c1-42b1-bd6a-64981e87d87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChessEloNN",
   "language": "python",
   "name": "chesselonn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
