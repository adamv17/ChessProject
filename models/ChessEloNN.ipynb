{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2007fc0a-d430-4027-a418-841b33c6ade1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\USER\\anaconda3\\envs\\chesnn\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aba8aa5d-30bc-4f64-8eaa-cfd45c4f7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-47c89b012d4b9249\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-47c89b012d4b9249\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!taskkill /IM \"tensorboard.exe\" /F\n",
    "!rmdir /S /Q %temp%\\.tensorboard-info\n",
    "%tensorboard --logdir=runs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6daf1b5-3041-4312-9860-4521a347ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "data_params = {'batch_size':128, \n",
    "               'shuffle':True}\n",
    "\n",
    "# validation params\n",
    "val_params = {'batch_size': 1, 'shuffle': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08478b4e-3565-4977-ae10-8e5d833a09dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# dataset \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, evals, games, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.evals = evals\n",
    "        self.games = games\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "         # Load data and get label\n",
    "        X = self.evals[ID]\n",
    "        X2 = self.games[ID]\n",
    "        y = self.labels[ID]\n",
    "        return X, X2, y\n",
    "    \n",
    "samples = torch.load('../data/X.pt')\n",
    "partition = {'train': list(range(17000)), 'dev': list(range(17000, 18000)), 'test': []}\n",
    "games = torch.load('../data/X2.pt')\n",
    "labels = torch.load('../data/Y.pt')\n",
    "# data loader\n",
    "training_set = Dataset(samples, games, partition['train'], labels)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **data_params)\n",
    "\n",
    "validation_set = Dataset(samples, games, partition['dev'], labels)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **val_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb28f5d2-22c4-4b4e-b988-0adf02bb80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef566ac-64eb-4936-94f3-87c7a80c058b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn model\n",
    "class EloNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.evl = torch.nn.Sequential(\n",
    "            torch.nn.Conv1d(in_channels=1, out_channels=200, kernel_size=20),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(in_features=6200, out_features=50),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(in_features=50, out_features=50),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "        )\n",
    "        self.game = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=64, out_features=512),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(in_features=512, out_features=128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(in_features=128, out_features=128),\n",
    "            torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc_combine = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=6450, out_features=100),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Linear(in_features=100, out_features=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        e = self.evl(input1)\n",
    "        g = self.game(input2)\n",
    "        combined = torch.cat((g.view(g.size(0), -1),\n",
    "                              e.view(e.size(0), -1)), dim=1)\n",
    "        out = self.fc_combine(combined)\n",
    "        return out\n",
    "    \n",
    "model = EloNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b5a7958-f66a-4420-ab64-e4f5593a7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "learning_rate=1e-3\n",
    "epochs=150 # 2000\n",
    "l2=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7dad611c-f7de-46c7-b178-e3ad371da2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def get_num_correct(predicted, actual):\n",
    "    count = 0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if abs(p[0] - actual[i][0]) < 100 and abs(p[1] - actual[i][1]) < 100:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0890508-58f8-44a0-be72-80dbfc60431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_correct: 127 loss: 5582315.505126953\n",
      "epoch: 1 total_correct: 0 loss: 417181.5974121094\n",
      "epoch: 2 total_correct: 0 loss: 414510.220703125\n",
      "epoch: 3 total_correct: 0 loss: 414310.0734863281\n",
      "epoch: 4 total_correct: 0 loss: 414062.9777832031\n",
      "epoch: 5 total_correct: 0 loss: 413858.90966796875\n",
      "epoch: 6 total_correct: 0 loss: 413848.90771484375\n",
      "epoch: 7 total_correct: 0 loss: 413797.53466796875\n",
      "epoch: 8 total_correct: 0 loss: 413783.380859375\n",
      "epoch: 9 total_correct: 0 loss: 413776.28955078125\n",
      "epoch: 10 total_correct: 0 loss: 413764.7333984375\n",
      "epoch: 11 total_correct: 0 loss: 413770.43896484375\n",
      "epoch: 12 total_correct: 0 loss: 413778.40869140625\n",
      "epoch: 13 total_correct: 0 loss: 413755.8454589844\n",
      "epoch: 14 total_correct: 0 loss: 413739.2158203125\n",
      "epoch: 15 total_correct: 0 loss: 413726.85595703125\n",
      "epoch: 16 total_correct: 0 loss: 413708.16748046875\n",
      "epoch: 17 total_correct: 0 loss: 413676.9943847656\n",
      "epoch: 18 total_correct: 0 loss: 413667.8957519531\n",
      "epoch: 19 total_correct: 0 loss: 413679.1003417969\n",
      "epoch: 20 total_correct: 0 loss: 413685.9697265625\n",
      "epoch: 21 total_correct: 0 loss: 413666.7451171875\n",
      "epoch: 22 total_correct: 0 loss: 413630.8859863281\n",
      "epoch: 23 total_correct: 0 loss: 413625.244140625\n",
      "epoch: 24 total_correct: 0 loss: 413615.0886230469\n",
      "epoch: 25 total_correct: 0 loss: 413583.5510253906\n",
      "epoch: 26 total_correct: 0 loss: 413599.38037109375\n",
      "epoch: 27 total_correct: 0 loss: 413588.9582519531\n",
      "epoch: 28 total_correct: 0 loss: 413562.8806152344\n",
      "epoch: 29 total_correct: 0 loss: 413566.49267578125\n",
      "epoch: 30 total_correct: 0 loss: 413546.4050292969\n",
      "epoch: 31 total_correct: 0 loss: 413542.259765625\n",
      "epoch: 32 total_correct: 0 loss: 413525.3400878906\n",
      "epoch: 33 total_correct: 0 loss: 413507.978515625\n",
      "epoch: 34 total_correct: 0 loss: 413495.5168457031\n",
      "epoch: 35 total_correct: 0 loss: 413471.1022949219\n",
      "epoch: 36 total_correct: 0 loss: 413471.8610839844\n",
      "epoch: 37 total_correct: 0 loss: 413448.5888671875\n",
      "epoch: 38 total_correct: 0 loss: 413435.43701171875\n",
      "epoch: 39 total_correct: 0 loss: 413427.5925292969\n",
      "epoch: 40 total_correct: 0 loss: 413414.72900390625\n",
      "epoch: 41 total_correct: 0 loss: 413427.5361328125\n",
      "epoch: 42 total_correct: 0 loss: 413402.3303222656\n",
      "epoch: 43 total_correct: 0 loss: 413398.83349609375\n",
      "epoch: 44 total_correct: 0 loss: 413398.4970703125\n",
      "epoch: 45 total_correct: 0 loss: 413384.7609863281\n",
      "epoch: 46 total_correct: 0 loss: 413364.7731933594\n",
      "epoch: 47 total_correct: 0 loss: 413372.5837402344\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3ebfb26715c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model.load_state_dict(torch.load('eval_game_model.pt'))\n",
    "model.train()\n",
    "model.to(device)\n",
    "# train model\n",
    "tb = SummaryWriter()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "tb = SummaryWriter()\n",
    "has_graphed = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for evals, games, labels in training_generator:\n",
    "        evals, games, labels = evals.float(), games.float(), labels.float()\n",
    "        evals = evals[:, None, :]\n",
    "        evals, games, labels = evals.to(device), games.to(device), labels.to(device)\n",
    "        preds = model(evals, games)\n",
    "        if epoch == 0 and not has_graphed:\n",
    "            tb.add_graph(model, [evals, games])\n",
    "            has_graphed = True\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct / len(training_generator), epoch)\n",
    "\n",
    "    tb.add_hparams(\n",
    "        {\"lr\": learning_rate, \"bsize\": data_params['batch_size'], \"shuffle\": data_params['shuffle']},\n",
    "        {\n",
    "            \"accuracy\": total_correct / len(training_generator),\n",
    "            \"loss\": total_loss,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()\n",
    "torch.save(model.state_dict(), 'eval_game_model_cross.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ebdc9ea-fb07-4fea-b6d5-2b9a448ce4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "statistics: \n",
      "std white = 297.5824004136536, std black = 288.5953691006514 \n",
      "mean white = -9.207428344726562, mean black = -3.506024658203125 \n",
      "max white = 1111.791748046875, max black = 1004.069091796875 \n",
      "min white = -862.5030517578125, min black = -923.33447265625\n",
      "total correct 519\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# validate model\n",
    "model.load_state_dict(torch.load('eval_game_model.pt'))\n",
    "device = 'cpu'\n",
    "model.to(device)\n",
    "model.eval()\n",
    "dev_num = len(validation_generator)\n",
    "predictions = np.empty((dev_num, 2))\n",
    "divs_white = np.empty(dev_num)\n",
    "divs_black = np.empty(dev_num)\n",
    "i = 0\n",
    "total_correct = 0\n",
    "for val_input, val_games, val_label in validation_generator:\n",
    "    val_input, val_games = val_input.float(), val_games.float()\n",
    "    val_input = val_input[:, None, :]\n",
    "    val_input, val_games = val_input.to(device), val_games.to(device)\n",
    "    y_hat = model(val_input, val_games)\n",
    "    y_hat = y_hat.detach().numpy()[0]\n",
    "    val_label = val_label.float().detach().numpy()[0]\n",
    "    div_white = y_hat[0] - val_label[0]\n",
    "    div_black = y_hat[1] - val_label[1]\n",
    "    if div_white < 100 and div_black < 100:\n",
    "        total_correct = total_correct + 1\n",
    "    predictions[i] = y_hat\n",
    "    divs_white[i] = div_white\n",
    "    divs_black[i] = div_black\n",
    "    i = i + 1\n",
    "str_res = f'\\nstatistics: \\nstd white = {np.std(divs_white)}, std black = {np.std(divs_black)} \\n' \\\n",
    "      f'mean white = {np.mean(divs_white)}, mean black = {np.mean(divs_black)} \\n' \\\n",
    "      f'max white = {np.max(divs_white)}, max black = {np.max(divs_black)} \\n' \\\n",
    "      f'min white = {np.min(divs_white)}, min black = {np.min(divs_black)}'\n",
    "print(str_res)\n",
    "print(f'total correct {total_correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a2e3c-18c1-42b1-bd6a-64981e87d87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChessEloNN",
   "language": "python",
   "name": "chesselonn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
