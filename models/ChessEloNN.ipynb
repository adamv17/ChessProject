{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a06c78b-9ecd-43bd-8c21-b80509b971d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\anaconda3\\envs\\chesnn\\lib\\site-packages\\torchvision\\io\\image.py:11: UserWarning: Failed to load image Python extension: Could not find module 'C:\\Users\\USER\\anaconda3\\envs\\chesnn\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "%load_ext tensorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aba8aa5d-30bc-4f64-8eaa-cfd45c4f7a2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bd44ec04240bca5d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bd44ec04240bca5d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!taskkill /IM \"tensorboard.exe\" /F\n",
    "!rmdir /S /Q %temp%\\.tensorboard-info\n",
    "%tensorboard --logdir=runs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6daf1b5-3041-4312-9860-4521a347ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "data_params = {'batch_size':128, \n",
    "               'shuffle':True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08478b4e-3565-4977-ae10-8e5d833a09dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# dataset \n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, samples, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        ID = self.list_IDs[index]\n",
    "\n",
    "         # Load data and get label\n",
    "        X = self.samples[ID]\n",
    "        y = self.labels[ID]\n",
    "        return X, y\n",
    "    \n",
    "samples = torch.load('../data/X.pt')\n",
    "partition = {'train': list(range(17000)), 'dev': list(range(17000, 18000)), 'test': []}\n",
    "labels = torch.load('../data/Y.pt')\n",
    "# data loader\n",
    "training_set = Dataset(samples, partition['train'], labels)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **data_params)\n",
    "\n",
    "validation_set = Dataset(samples, partition['dev'], labels)\n",
    "validation_generator = torch.utils.data.DataLoader(validation_set, **data_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb28f5d2-22c4-4b4e-b988-0adf02bb80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7ef566ac-64eb-4936-94f3-87c7a80c058b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EloNN(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=25, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=25, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn model\n",
    "class EloNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(50, 100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100, 25),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(25, 2),\n",
    "        )\n",
    "    \n",
    "    def forward(self, ml_in):\n",
    "        return self.layers(ml_in)\n",
    "    \n",
    "model = EloNN()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b5a7958-f66a-4420-ab64-e4f5593a7240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "learning_rate=1e-3\n",
    "epochs=2000 # 2000\n",
    "l2=1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7dad611c-f7de-46c7-b178-e3ad371da2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function\n",
    "def get_num_correct(predicted, actual):\n",
    "    count = 0\n",
    "    for i, p in enumerate(predicted):\n",
    "        if abs(p[0] - actual[i][0]) < 100 and abs(p[1] - actual[i][1]) < 100:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0890508-58f8-44a0-be72-80dbfc60431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 total_correct: 55 loss: 444388811.25\n",
      "epoch: 1 total_correct: 308 loss: 206671034.9375\n",
      "epoch: 2 total_correct: 407 loss: 154432508.8125\n",
      "epoch: 3 total_correct: 446 loss: 132563249.375\n",
      "epoch: 4 total_correct: 425 loss: 117660954.4375\n",
      "epoch: 5 total_correct: 506 loss: 105157968.3125\n",
      "epoch: 6 total_correct: 549 loss: 94223101.71875\n",
      "epoch: 7 total_correct: 563 loss: 84900925.9375\n",
      "epoch: 8 total_correct: 613 loss: 77404941.25\n",
      "epoch: 9 total_correct: 692 loss: 72130842.375\n",
      "epoch: 10 total_correct: 712 loss: 68587395.0625\n",
      "epoch: 11 total_correct: 766 loss: 65563893.46875\n",
      "epoch: 12 total_correct: 787 loss: 63159546.09375\n",
      "epoch: 13 total_correct: 833 loss: 60866292.125\n",
      "epoch: 14 total_correct: 863 loss: 58185053.8125\n",
      "epoch: 15 total_correct: 948 loss: 56478744.609375\n",
      "epoch: 16 total_correct: 984 loss: 54376457.328125\n",
      "epoch: 17 total_correct: 1032 loss: 52118418.5625\n",
      "epoch: 18 total_correct: 1004 loss: 50360074.953125\n",
      "epoch: 19 total_correct: 1027 loss: 48221942.96875\n",
      "epoch: 20 total_correct: 1062 loss: 46350596.15625\n",
      "epoch: 21 total_correct: 1132 loss: 44637643.5\n",
      "epoch: 22 total_correct: 1128 loss: 42836712.078125\n",
      "epoch: 23 total_correct: 1188 loss: 40299536.90625\n",
      "epoch: 24 total_correct: 1180 loss: 38540955.953125\n",
      "epoch: 25 total_correct: 1253 loss: 36261590.640625\n",
      "epoch: 26 total_correct: 1246 loss: 34708075.296875\n",
      "epoch: 27 total_correct: 1221 loss: 33717568.34375\n",
      "epoch: 28 total_correct: 1316 loss: 32888613.078125\n",
      "epoch: 29 total_correct: 1264 loss: 31487785.1953125\n",
      "epoch: 30 total_correct: 1293 loss: 31413716.7265625\n",
      "epoch: 31 total_correct: 1295 loss: 30201464.734375\n",
      "epoch: 32 total_correct: 1298 loss: 29624056.4765625\n",
      "epoch: 33 total_correct: 1336 loss: 29215478.8984375\n",
      "epoch: 34 total_correct: 1335 loss: 28145885.7265625\n",
      "epoch: 35 total_correct: 1328 loss: 28219905.96875\n",
      "epoch: 36 total_correct: 1321 loss: 27549340.046875\n",
      "epoch: 37 total_correct: 1329 loss: 27225063.453125\n",
      "epoch: 38 total_correct: 1357 loss: 26996715.03125\n",
      "epoch: 39 total_correct: 1303 loss: 26837000.828125\n",
      "epoch: 40 total_correct: 1301 loss: 26737565.46875\n",
      "epoch: 41 total_correct: 1346 loss: 26032192.7578125\n",
      "epoch: 42 total_correct: 1312 loss: 25970594.296875\n",
      "epoch: 43 total_correct: 1317 loss: 25603211.53125\n",
      "epoch: 44 total_correct: 1360 loss: 25317006.59375\n",
      "epoch: 45 total_correct: 1336 loss: 25264570.6875\n",
      "epoch: 46 total_correct: 1322 loss: 24846653.5546875\n",
      "epoch: 47 total_correct: 1331 loss: 24665313.8125\n",
      "epoch: 48 total_correct: 1358 loss: 24553881.90625\n",
      "epoch: 49 total_correct: 1375 loss: 24064573.8203125\n",
      "epoch: 50 total_correct: 1369 loss: 24744730.6484375\n",
      "epoch: 51 total_correct: 1385 loss: 23812521.8125\n",
      "epoch: 52 total_correct: 1383 loss: 23606068.203125\n",
      "epoch: 53 total_correct: 1368 loss: 23031442.546875\n",
      "epoch: 54 total_correct: 1380 loss: 23179041.65625\n",
      "epoch: 55 total_correct: 1424 loss: 23053021.296875\n",
      "epoch: 56 total_correct: 1370 loss: 22362757.1484375\n",
      "epoch: 57 total_correct: 1382 loss: 21792347.8125\n",
      "epoch: 58 total_correct: 1404 loss: 21414893.265625\n",
      "epoch: 59 total_correct: 1384 loss: 21502890.828125\n",
      "epoch: 60 total_correct: 1380 loss: 21201990.6875\n",
      "epoch: 61 total_correct: 1389 loss: 21116514.125\n",
      "epoch: 62 total_correct: 1373 loss: 22359072.6953125\n",
      "epoch: 63 total_correct: 1436 loss: 20373574.0234375\n",
      "epoch: 64 total_correct: 1409 loss: 20057460.6796875\n",
      "epoch: 65 total_correct: 1402 loss: 19727563.5\n",
      "epoch: 66 total_correct: 1463 loss: 19138351.53125\n",
      "epoch: 67 total_correct: 1457 loss: 18707117.6796875\n",
      "epoch: 68 total_correct: 1427 loss: 18329049.0234375\n",
      "epoch: 69 total_correct: 1408 loss: 18381219.5390625\n",
      "epoch: 70 total_correct: 1473 loss: 17812574.3828125\n",
      "epoch: 71 total_correct: 1482 loss: 17217697.140625\n",
      "epoch: 72 total_correct: 1475 loss: 16945955.8515625\n",
      "epoch: 73 total_correct: 1495 loss: 17032010.2265625\n",
      "epoch: 74 total_correct: 1494 loss: 16466937.0234375\n",
      "epoch: 75 total_correct: 1520 loss: 16234965.015625\n",
      "epoch: 76 total_correct: 1457 loss: 15822291.4296875\n",
      "epoch: 77 total_correct: 1460 loss: 16547036.703125\n",
      "epoch: 78 total_correct: 1506 loss: 16288415.3984375\n",
      "epoch: 79 total_correct: 1564 loss: 14661638.6796875\n",
      "epoch: 80 total_correct: 1566 loss: 14458798.90625\n",
      "epoch: 81 total_correct: 1509 loss: 14700220.71875\n",
      "epoch: 82 total_correct: 1581 loss: 14384030.4453125\n",
      "epoch: 83 total_correct: 1593 loss: 14082365.9453125\n",
      "epoch: 84 total_correct: 1552 loss: 13532670.5859375\n",
      "epoch: 85 total_correct: 1561 loss: 13818543.8515625\n",
      "epoch: 86 total_correct: 1537 loss: 13877360.7421875\n",
      "epoch: 87 total_correct: 1556 loss: 13228033.671875\n",
      "epoch: 88 total_correct: 1628 loss: 13001216.5859375\n",
      "epoch: 89 total_correct: 1608 loss: 12667162.2578125\n",
      "epoch: 90 total_correct: 1633 loss: 12619744.4609375\n",
      "epoch: 91 total_correct: 1633 loss: 12689802.4140625\n",
      "epoch: 92 total_correct: 1611 loss: 12393314.1640625\n",
      "epoch: 93 total_correct: 1687 loss: 12083156.9140625\n",
      "epoch: 94 total_correct: 1663 loss: 12399557.9765625\n",
      "epoch: 95 total_correct: 1652 loss: 12033084.859375\n",
      "epoch: 96 total_correct: 1692 loss: 11981813.74609375\n",
      "epoch: 97 total_correct: 1674 loss: 11919186.82421875\n",
      "epoch: 98 total_correct: 1692 loss: 11399259.87109375\n",
      "epoch: 99 total_correct: 1672 loss: 11284240.6171875\n",
      "epoch: 100 total_correct: 1707 loss: 11627681.15625\n",
      "epoch: 101 total_correct: 1731 loss: 10848675.3828125\n",
      "epoch: 102 total_correct: 1726 loss: 11319403.78515625\n",
      "epoch: 103 total_correct: 1704 loss: 10975502.51953125\n",
      "epoch: 104 total_correct: 1750 loss: 10786864.51953125\n",
      "epoch: 105 total_correct: 1713 loss: 11157636.24609375\n",
      "epoch: 106 total_correct: 1764 loss: 10571378.6796875\n",
      "epoch: 107 total_correct: 1770 loss: 10911327.765625\n",
      "epoch: 108 total_correct: 1788 loss: 10278929.9609375\n",
      "epoch: 109 total_correct: 1823 loss: 10234270.23046875\n",
      "epoch: 110 total_correct: 1822 loss: 10194939.765625\n",
      "epoch: 111 total_correct: 1771 loss: 10420568.80078125\n",
      "epoch: 112 total_correct: 1802 loss: 10262776.15625\n",
      "epoch: 113 total_correct: 1857 loss: 9752355.88671875\n",
      "epoch: 114 total_correct: 1736 loss: 9915321.42578125\n",
      "epoch: 115 total_correct: 1772 loss: 10097808.796875\n",
      "epoch: 116 total_correct: 1808 loss: 10328045.61328125\n",
      "epoch: 117 total_correct: 1756 loss: 10399195.265625\n",
      "epoch: 118 total_correct: 1821 loss: 10055859.94921875\n",
      "epoch: 119 total_correct: 1814 loss: 10695572.37890625\n",
      "epoch: 120 total_correct: 1821 loss: 10068276.29296875\n",
      "epoch: 121 total_correct: 1799 loss: 9648389.60546875\n",
      "epoch: 122 total_correct: 1831 loss: 9431629.78515625\n",
      "epoch: 123 total_correct: 1781 loss: 9590400.08203125\n",
      "epoch: 124 total_correct: 1879 loss: 9348501.71484375\n",
      "epoch: 125 total_correct: 1798 loss: 9855139.078125\n",
      "epoch: 126 total_correct: 1904 loss: 9455850.30859375\n",
      "epoch: 127 total_correct: 1799 loss: 9559677.640625\n",
      "epoch: 128 total_correct: 1811 loss: 9642487.69921875\n",
      "epoch: 129 total_correct: 1865 loss: 9637084.40625\n",
      "epoch: 130 total_correct: 1827 loss: 9632221.109375\n",
      "epoch: 131 total_correct: 1827 loss: 9645659.59765625\n",
      "epoch: 132 total_correct: 1853 loss: 9017096.63671875\n",
      "epoch: 133 total_correct: 1885 loss: 9294278.4765625\n",
      "epoch: 134 total_correct: 1850 loss: 9000164.5859375\n",
      "epoch: 135 total_correct: 1851 loss: 9308553.46484375\n",
      "epoch: 136 total_correct: 1907 loss: 9403453.46484375\n",
      "epoch: 137 total_correct: 1892 loss: 9023409.8671875\n",
      "epoch: 138 total_correct: 1859 loss: 9067697.39453125\n",
      "epoch: 139 total_correct: 1882 loss: 9307648.109375\n",
      "epoch: 140 total_correct: 1894 loss: 8972768.140625\n",
      "epoch: 141 total_correct: 1887 loss: 9243927.46875\n",
      "epoch: 142 total_correct: 1932 loss: 9131564.37890625\n",
      "epoch: 143 total_correct: 1875 loss: 8883508.55078125\n",
      "epoch: 144 total_correct: 1918 loss: 8901689.05859375\n",
      "epoch: 145 total_correct: 1872 loss: 9187908.640625\n",
      "epoch: 146 total_correct: 1923 loss: 8897490.11328125\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "tb = SummaryWriter()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=l2)\n",
    "criterion = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "tb = SummaryWriter()\n",
    "has_graphed = False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "\n",
    "    for inputs, labels in training_generator:\n",
    "        inputs = inputs.float()\n",
    "        labels = labels.float()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        preds = model(inputs)\n",
    "        if epoch == 0 and not has_graphed:\n",
    "            tb.add_graph(model, inputs)\n",
    "            has_graphed = True\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        total_loss += loss.item()\n",
    "        total_correct += get_num_correct(preds, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    tb.add_scalar(\"Loss\", total_loss, epoch)\n",
    "    tb.add_scalar(\"Correct\", total_correct, epoch)\n",
    "    tb.add_scalar(\"Accuracy\", total_correct / len(training_generator), epoch)\n",
    "\n",
    "    tb.add_histogram(\"linear1.bias\", model.layers[0].bias, epoch)\n",
    "    tb.add_histogram(\"linear1.weight\", model.layers[0].weight, epoch)\n",
    "    tb.add_histogram(\"linear2.bias\", model.layers[2].bias, epoch)\n",
    "    tb.add_histogram(\"linear2.weight\", model.layers[2].weight, epoch)\n",
    "    tb.add_histogram(\"linear3.bias\", model.layers[4].bias, epoch)\n",
    "    tb.add_histogram(\"linear3.weight\", model.layers[4].weight, epoch)\n",
    "        \n",
    "    tb.add_hparams(\n",
    "        {\"lr\": learning_rate, \"bsize\": data_params['batch_size'], \"shuffle\": data_params['shuffle']},\n",
    "        {\n",
    "            \"accuracy\": total_correct / len(training_generator),\n",
    "            \"loss\": total_loss,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    print(\"epoch:\", epoch, \"total_correct:\", total_correct, \"loss:\", total_loss)\n",
    "    \n",
    "tb.close()\n",
    "torch.save(model.state_dict(), 'multi_layer_perceptron.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebdc9ea-fb07-4fea-b6d5-2b9a448ce4ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91a2e3c-18c1-42b1-bd6a-64981e87d87d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChessEloNN",
   "language": "python",
   "name": "chesselonn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
